{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4484097",
   "metadata": {},
   "source": [
    "自定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9721859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b32d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(output, target):\n",
    "    loss = torch.mean((output - target)**2)\n",
    "    return loss\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self,weight=None,size_average=True):\n",
    "        super(DiceLoss,self).__init__()\n",
    "        \n",
    "    def forward(self,inputs,targets,smooth=1):\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        intersection = (inputs * targets).sum()                   \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        return 1 - dice\n",
    "\n",
    "# 使用方法    \n",
    "#criterion = DiceLoss()\n",
    "#loss = criterion(input,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df7463",
   "metadata": {},
   "source": [
    "动态调整学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4734305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "官方API\n",
    "PyTorch已经在torch.optim.lr_scheduler封装好了一些动态调整学习率的方法\n",
    "这些scheduler都是继承自_LRScheduler类\n",
    "\n",
    "lr_scheduler.LambdaLR\n",
    "lr_scheduler.MultiplicativeLR\n",
    "lr_scheduler.StepLR\n",
    "lr_scheduler.MultiStepLR\n",
    "lr_scheduler.ExponentialLR\n",
    "lr_scheduler.CosineAnnealingLR\n",
    "lr_scheduler.ReduceLROnPlateau\n",
    "lr_scheduler.CyclicLR\n",
    "lr_scheduler.OneCycleLR\n",
    "lr_scheduler.CosineAnnealingWarmRestarts\n",
    "lr_scheduler.ConstantLR\n",
    "lr_scheduler.LinearLR\n",
    "lr_scheduler.PolynomialLR\n",
    "lr_scheduler.ChainedScheduler\n",
    "lr_scheduler.SequentialLR\n",
    "\"\"\"\n",
    "# # 选择一种优化器\n",
    "# optimizer = torch.optim.Adam(...) \n",
    "# # 选择上面提到的一种或多种动态调整学习率的方法\n",
    "# scheduler1 = torch.optim.lr_scheduler.... \n",
    "# scheduler2 = torch.optim.lr_scheduler....\n",
    "# ...\n",
    "# schedulern = torch.optim.lr_scheduler....\n",
    "# # 进行训练\n",
    "# for epoch in range(100):\n",
    "#     train(...)\n",
    "#     validate(...)\n",
    "#     optimizer.step()\n",
    "#     # 需要在优化器参数更新之后再动态调整学习率\n",
    "# # scheduler的优化是在每一轮后面进行的\n",
    "# scheduler1.step() \n",
    "# ...\n",
    "# schedulern.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "自定义scheduler\n",
    "自定义函数adjust_learning_rate来改变param_group中lr的值\n",
    "\"\"\"\n",
    "# 假设我们现在正在做实验，需要学习率每30轮下降为原来的1/10\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args.lr,momentum = 0.9)\n",
    "for epoch in range(10):\n",
    "    train(...)\n",
    "    validate(...)\n",
    "    adjust_learning_rate(optimizer,epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ba3ac7",
   "metadata": {},
   "source": [
    "模型微调-torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d184c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "模型微调的流程\n",
    "在源数据集上预训练一个神经网络模型，即源模型。\n",
    "创建一个新的神经网络模型，即目标模型。它复制了源模型上除了输出层外的所有模型设计及其参数。\n",
    "我们假设这些模型参数包含了源数据集上学习到的知识，且这些知识同样适用于目标数据集。\n",
    "我们还假设源模型的输出层跟源数据集的标签紧密相关，因此在目标模型中不予采用。\n",
    "为目标模型添加一个输出⼤小为目标数据集类别个数的输出层，并随机初始化该层的模型参数。\n",
    "在目标数据集上训练目标模型。我们将从头训练输出层，而其余层的参数都是基于源模型的参数微调得到的\n",
    "\"\"\"\n",
    "# 使用已有模型结构,以torchvision中的常见模型为例\n",
    "# 实例化网络\n",
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "# resnet18 = models.resnet18(pretrained=False)  等价于与上面的表达式\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v2()\n",
    "mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()\n",
    "\n",
    "# 还可以将自己的权重下载下来放到同文件夹下，然后再将参数加载网络\n",
    "self.model = models.resnet50(pretrained=False)\n",
    "self.model.load_state_dict(torch.load('./model/resnet50-19c8e357.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41051b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练特定层\n",
    "# 在默认情况下，参数的属性.requires_grad = True，如果我们从头开始训练或微调不需要注意这里。\n",
    "# 但如果我们正在提取特征并且只想为新初始化的层计算梯度，其他参数不进行改变。\n",
    "# 那我们就需要通过设置requires_grad = False来冻结部分层\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "# 使用resnet18为例的将1000类改为4类，但是仅改变最后一层的模型参数，不改变特征提取的模型参数；\n",
    "# 注意我们先冻结模型参数的梯度，再对模型输出部分的全连接层进行修改，这样修改后的全连接层的参数就是可计算梯度的\n",
    "# 之后在训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层。\n",
    "import torchvision.models as models\n",
    "# 冻结参数的梯度\n",
    "feature_extract = True\n",
    "model = models.resnet18(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "# 修改模型\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=num_ftrs, out_features=4, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da0fee",
   "metadata": {},
   "source": [
    "模型微调-timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84989a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "常见的预训练模型库，叫做timm\n",
    "可以通过timm.list_models()方法查看timm提供的预训练模型\n",
    "\"\"\"\n",
    "# 通过访问模型的default_cfg属性来进行查看模型的具体参数\n",
    "# 通过timm.create_model()的方法来进行模型的创建,同时可以修改模型\n",
    "model = timm.create_model('resnet34',num_classes=10,pretrained=True)\n",
    "model.default_cfg\n",
    "\n",
    "# 模型保存和加载\n",
    "torch.save(model.state_dict(),'./checkpoint/timm_model.pth')\n",
    "model.load_state_dict(torch.load('./checkpoint/timm_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048a058",
   "metadata": {},
   "source": [
    "半精度训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用autocast配置半精度训练\n",
    "from torch.cuda.amp import autocast\n",
    "# 用autocast装饰模型中的forward函数\n",
    "@autocast()   \n",
    "def forward(self, x):\n",
    "    ...\n",
    "    return x\n",
    "# 训练过程\n",
    "for x in train_loader:\n",
    "\tx = x.cuda()\n",
    "\twith autocast():\n",
    "            output = model(x)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ef227",
   "metadata": {},
   "source": [
    "数据增强-imgaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 针对有限数据问题的解决方案，数据增强技术\n",
    "# imgaug是计算机视觉任务中常用的一个数据增强的包\n",
    "\n",
    "# 单张图片处理\n",
    "import imageio\n",
    "import imgaug as ia\n",
    "%matplotlib inline\n",
    "\n",
    "# 图片的读取\n",
    "img = imageio.imread(\"./Lenna.jpg\")\n",
    "\n",
    "# 使用Image进行读取\n",
    "# img = Image.open(\"./Lenna.jpg\")\n",
    "# image = np.array(img)\n",
    "# ia.imshow(image)\n",
    "\n",
    "# 可视化图片\n",
    "ia.imshow(img)\n",
    "\n",
    "# imgaug包含了许多从Augmenter继承的数据增强的操作，以Affine为例\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "# 设置随机数种子\n",
    "ia.seed(4)\n",
    "\n",
    "# 实例化方法\n",
    "rotate = iaa.Affine(rotate=(-4,45))\n",
    "img_aug = rotate(image=img)\n",
    "ia.imshow(img_aug)\n",
    "\n",
    "# 对一张图片做多种数据增强处理。需要利用imgaug.augmenters.Sequential()来构造数据增强的pipline\n",
    "# 与torchvison.transforms.Compose()相类似\n",
    "iaa.Sequential(children=None, # Augmenter集合\n",
    "               random_order=False, # 是否对每个batch使用不同顺序的Augmenter list\n",
    "               name=None,\n",
    "               deterministic=False,\n",
    "               random_state=None)\n",
    "# 构建处理序列\n",
    "aug_seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-25,25)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(10,60)),\n",
    "    iaa.Crop(percent=(0,0.2))\n",
    "])\n",
    "# 对图片进行处理，image不可以省略，也不能写成images\n",
    "image_aug = aug_seq(image=img)\n",
    "ia.imshow(image_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对批次图片进行处理\n",
    "\n",
    "#对批次的图片以同一种方式处理\n",
    "images = [img,img,img,img,]\n",
    "images_aug = rotate(images=images)\n",
    "ia.imshow(np.hstack(images_aug))\n",
    "\n",
    "# 也可以对批次的图片使用多种增强方法\n",
    "aug_seq = iaa.Sequential([\n",
    "    iaa.Affine(rotate=(-25, 25)),\n",
    "    iaa.AdditiveGaussianNoise(scale=(10, 60)),\n",
    "    iaa.Crop(percent=(0, 0.2))\n",
    "])\n",
    "\n",
    "# 传入时需要指明是images参数\n",
    "images_aug = aug_seq.augment_images(images = images)\n",
    "#images_aug = aug_seq(images = images) \n",
    "ia.imshow(np.hstack(images_aug))\n",
    "\n",
    "# 对批次的图片分部分处理\n",
    "# 通过imgaug.augmenters.Sometimes()对batch中的一部分图片应用一部分Augmenters,剩下的图片应用另外的Augmenters\n",
    "iaa.Sometimes(p=0.5,  # 代表划分比例\n",
    "              then_list=None,  # Augmenter集合。p概率的图片进行变换的Augmenters。\n",
    "              else_list=None,  #1-p概率的图片会被进行变换的Augmenters。注意变换的图片应用的Augmenter只能是then_list或者else_list中的一个。\n",
    "              name=None,\n",
    "              deterministic=False,\n",
    "              random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对不同大小的图片进行处理\n",
    "# 构建pipline\n",
    "seq = iaa.Sequential([\n",
    "    iaa.CropAndPad(percent=(-0.2, 0.2), pad_mode=\"edge\"),  # crop and pad images\n",
    "    iaa.AddToHueAndSaturation((-60, 60)),  # change their color\n",
    "    iaa.ElasticTransformation(alpha=90, sigma=9),  # water-like effect\n",
    "    iaa.Cutout()  # replace one squared area within the image by a constant intensity value\n",
    "], random_order=True)\n",
    "\n",
    "# 加载不同大小的图片\n",
    "images_different_sizes = [\n",
    "    imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/e/ed/BRACHYLAGUS_IDAHOENSIS.jpg\"),\n",
    "    imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/c/c9/Southern_swamp_rabbit_baby.jpg\"),\n",
    "    imageio.imread(\"https://upload.wikimedia.org/wikipedia/commons/9/9f/Lower_Keys_marsh_rabbit.jpg\")\n",
    "]\n",
    "\n",
    "# 对图片进行增强\n",
    "images_aug = seq(images=images_different_sizes)\n",
    "\n",
    "# 可视化结果\n",
    "print(\"Image 0 (input shape: %s, output shape: %s)\" % (images_different_sizes[0].shape, images_aug[0].shape))\n",
    "ia.imshow(np.hstack([images_different_sizes[0], images_aug[0]]))\n",
    "\n",
    "print(\"Image 1 (input shape: %s, output shape: %s)\" % (images_different_sizes[1].shape, images_aug[1].shape))\n",
    "ia.imshow(np.hstack([images_different_sizes[1], images_aug[1]]))\n",
    "\n",
    "print(\"Image 2 (input shape: %s, output shape: %s)\" % (images_different_sizes[2].shape, images_aug[2].shape))\n",
    "ia.imshow(np.hstack([images_different_sizes[2], images_aug[2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995fdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgaug在PyTorch的应用\n",
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "# 构建pipline\n",
    "tfs = transforms.Compose([\n",
    "    iaa.Sequential([\n",
    "        iaa.flip.Fliplr(p=0.5),\n",
    "        iaa.flip.Flipud(p=0.5),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 0.1)),\n",
    "        iaa.MultiplyBrightness(mul=(0.65, 1.35)),\n",
    "    ]).augment_image,\n",
    "    # 不要忘记了使用ToTensor()\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, n_images, n_classes, transform=None):\n",
    "\t\t# 图片的读取，建议使用imageio\n",
    "        self.images = np.random.randint(0, 255,\n",
    "                                        (n_images, 224, 224, 3),\n",
    "                                        dtype=np.uint8)\n",
    "        self.targets = np.random.randn(n_images, n_classes)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = self.images[item]\n",
    "        target = self.targets[item]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "def worker_init_fn(worker_id):\n",
    "    imgaug.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "\n",
    "custom_ds = CustomDataset(n_images=50, n_classes=10, transform=tfs)\n",
    "custom_dl = DataLoader(custom_ds, batch_size=64,\n",
    "                       num_workers=4, pin_memory=True, \n",
    "                       worker_init_fn=worker_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa77f19",
   "metadata": {},
   "source": [
    "使用argparse进行调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# argparse的作用就是将命令行传入的其他参数进行解析、保存和使用\n",
    "# 将argparse的使用归纳为以下三个步骤\n",
    "# 创建ArgumentParser()对象，调用add_argument()方法添加参数，使用parse_args()解析参数\n",
    "\n",
    "# demo.py\n",
    "import argparse\n",
    "\n",
    "# 创建ArgumentParser()对象\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# 添加参数\n",
    "parser.add_argument('-o', '--output', action='store_true', \n",
    "    help=\"shows output\")\n",
    "# action = `store_true` 会将output参数记录为True\n",
    "# type 规定了参数的格式\n",
    "# default 规定了默认值\n",
    "parser.add_argument('--lr', type=float, default=3e-5, help='select the learning rate, default=1e-3') \n",
    "\n",
    "parser.add_argument('--batch_size', type=int, required=True, help='input batch size')  \n",
    "# 使用parse_args()解析函数\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.output:\n",
    "    print(\"This is some output\")\n",
    "    print(f\"learning rate:{args.lr} \")\n",
    "\n",
    "# 命令行使用python demo.py --lr 3e-4 --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca33a3",
   "metadata": {},
   "source": [
    "更加高效使用argparse修改超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般会将有关超参数的操作写在config.py，在train.py或者其他文件导入就可以\n",
    "import argparse  \n",
    "  \n",
    "def get_options(parser=argparse.ArgumentParser()):  \n",
    "  \n",
    "    parser.add_argument('--workers', type=int, default=0,  \n",
    "                        help='number of data loading workers, you had better put it '  \n",
    "                              '4 times of your gpu')  \n",
    "  \n",
    "    parser.add_argument('--batch_size', type=int, default=4, help='input batch size, default=64')  \n",
    "  \n",
    "    parser.add_argument('--niter', type=int, default=10, help='number of epochs to train for, default=10')  \n",
    "  \n",
    "    parser.add_argument('--lr', type=float, default=3e-5, help='select the learning rate, default=1e-3')  \n",
    "  \n",
    "    parser.add_argument('--seed', type=int, default=118, help=\"random seed\")  \n",
    "  \n",
    "    parser.add_argument('--cuda', action='store_true', default=True, help='enables cuda')  \n",
    "    parser.add_argument('--checkpoint_path',type=str,default='',  \n",
    "                        help='Path to load a previous trained model if not empty (default empty)')  \n",
    "    parser.add_argument('--output',action='store_true',default=True,help=\"shows output\")  \n",
    "  \n",
    "    opt = parser.parse_args()  \n",
    "  \n",
    "    if opt.output:  \n",
    "        print(f'num_workers: {opt.workers}')  \n",
    "        print(f'batch_size: {opt.batch_size}')  \n",
    "        print(f'epochs (niters) : {opt.niter}')  \n",
    "        print(f'learning rate : {opt.lr}')  \n",
    "        print(f'manual_seed: {opt.seed}')  \n",
    "        print(f'cuda enable: {opt.cuda}')  \n",
    "        print(f'checkpoint_path: {opt.checkpoint_path}')  \n",
    "  \n",
    "    return opt  \n",
    "  \n",
    "if __name__ == '__main__':  \n",
    "    opt = get_options()\n",
    "\n",
    "# 随后在train.py等其他文件，我们就可以使用下面的这样的结构来调用参数\n",
    "# 导入必要库\n",
    "...\n",
    "import config\n",
    "\n",
    "opt = config.get_options()\n",
    "\n",
    "manual_seed = opt.seed\n",
    "num_workers = opt.workers\n",
    "batch_size = opt.batch_size\n",
    "lr = opt.lr\n",
    "niters = opt.niters\n",
    "checkpoint_path = opt.checkpoint_path\n",
    "\n",
    "# 随机数的设置，保证复现结果\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tset_seed(manual_seed)\n",
    "\tfor epoch in range(niters):\n",
    "\t\ttrain(model,lr,batch_size,num_workers,checkpoint_path)\n",
    "\t\tval(model,lr,batch_size,num_workers,checkpoint_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "universe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
